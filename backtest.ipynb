{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ee5a6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Loading Cryptocurrency Data\n",
      "============================================================\n",
      "\n",
      "üìä Loading BTC data from 7 file(s)...\n",
      "   ‚úì Loaded BTCUSDT_2019_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded BTCUSDT_2020_minute.Last.txt: 527,040 rows\n",
      "   ‚úì Loaded BTCUSDT_2021_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded BTCUSDT_2022_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded BTCUSDT_2023_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded BTCUSDT_2024_minute.Last.txt: 527,040 rows\n",
      "   ‚úì Loaded BTCUSDT_2025_minute.Last.txt: 499,680 rows\n",
      "‚úÖ BTC data loaded: 3,656,160 total rows\n",
      "   Date range: 2019-01-01 00:00:00+00:00 to 2025-12-13 23:59:00+00:00\n",
      "\n",
      "üìä Loading ETH data from 7 file(s)...\n",
      "   ‚úì Loaded ETHUSDT_2019_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded ETHUSDT_2020_minute.Last.txt: 527,040 rows\n",
      "   ‚úì Loaded ETHUSDT_2021_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded ETHUSDT_2022_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded ETHUSDT_2023_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded ETHUSDT_2024_minute.Last.txt: 527,040 rows\n",
      "   ‚úì Loaded ETHUSDT_2025_minute.Last.txt: 499,680 rows\n",
      "‚úÖ ETH data loaded: 3,656,160 total rows\n",
      "   Date range: 2019-01-01 00:00:00+00:00 to 2025-12-13 23:59:00+00:00\n",
      "\n",
      "üìä Loading SOL data from 3 file(s)...\n",
      "   ‚úì Loaded SOLUSDT_2023_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded SOLUSDT_2024_minute.Last.txt: 527,040 rows\n",
      "   ‚úì Loaded SOLUSDT_2025_minute.Last.txt: 499,680 rows\n",
      "‚úÖ SOL data loaded: 1,552,320 total rows\n",
      "   Date range: 2023-01-01 00:00:00+00:00 to 2025-12-13 23:59:00+00:00\n",
      "\n",
      "üìä Loading XRP data from 7 file(s)...\n",
      "   ‚úì Loaded XRPUSDT_2019_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded XRPUSDT_2020_minute.Last.txt: 527,040 rows\n",
      "   ‚úì Loaded XRPUSDT_2021_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded XRPUSDT_2022_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded XRPUSDT_2023_minute.Last.txt: 525,600 rows\n",
      "   ‚úì Loaded XRPUSDT_2024_minute.Last.txt: 527,040 rows\n",
      "   ‚úì Loaded XRPUSDT_2025_minute.Last.txt: 501,120 rows\n",
      "‚úÖ XRP data loaded: 3,657,600 total rows\n",
      "   Date range: 2019-01-01 00:00:00+00:00 to 2025-12-14 23:59:00+00:00\n",
      "\n",
      "============================================================\n",
      "Data Loading Complete!\n",
      "============================================================\n",
      "\n",
      "Available DataFrames:\n",
      "  - btc_data: 3,656,160 rows\n",
      "  - eth_data: 3,656,160 rows\n",
      "  - sol_data: 1,552,320 rows\n",
      "  - xrp_data: 3,657,600 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load all data files for a cryptocurrency\n",
    "def load_crypto_data(crypto_name, data_folder):\n",
    "    \"\"\"\n",
    "    Load all .Last.txt files for a cryptocurrency and combine them into a single DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    crypto_name : str\n",
    "        Name of the cryptocurrency (e.g., 'BTC', 'ETH', 'SOL', 'XRP')\n",
    "    data_folder : str\n",
    "        Path to the folder containing the data files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Combined DataFrame with columns: DateTime, Open, High, Low, Close, Volume\n",
    "    \"\"\"\n",
    "    # Find all .Last.txt files in the folder (including subdirectories)\n",
    "    txt_files = glob.glob(os.path.join(data_folder, \"**/*.Last.txt\"), recursive=True)\n",
    "    \n",
    "    if not txt_files:\n",
    "        print(f\"‚ö†Ô∏è Warning: No .Last.txt files found in {data_folder}\")\n",
    "        return None\n",
    "    \n",
    "    # Sort files to ensure chronological order\n",
    "    txt_files.sort()\n",
    "    \n",
    "    print(f\"üìä Loading {crypto_name} data from {len(txt_files)} file(s)...\")\n",
    "    \n",
    "    all_dataframes = []\n",
    "    \n",
    "    for f in txt_files:\n",
    "        try:\n",
    "            # Read the file (semicolon-separated, no header)\n",
    "            df = pd.read_csv(f, sep=';', header=None, \n",
    "                           names=['DateTime', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "            \n",
    "            # Parse datetime (format: YYYYMMDD HHMMSS) and make timezone-aware (UTC)\n",
    "            df['DateTime'] = pd.to_datetime(df['DateTime'], format='%Y%m%d %H%M%S', utc=True)\n",
    "            \n",
    "            # Set DateTime as index\n",
    "            df.set_index('DateTime', inplace=True)\n",
    "            \n",
    "            all_dataframes.append(df)\n",
    "            print(f\"   ‚úì Loaded {os.path.basename(f)}: {len(df):,} rows\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚úó Error loading {os.path.basename(f)}: {e}\")\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        print(f\"‚ö†Ô∏è No data loaded for {crypto_name}\")\n",
    "        return None\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(all_dataframes, axis=0)\n",
    "    \n",
    "    # Sort by datetime to ensure proper order\n",
    "    combined_df.sort_index(inplace=True)\n",
    "    \n",
    "    # Remove duplicates if any\n",
    "    combined_df = combined_df[~combined_df.index.duplicated(keep='first')]\n",
    "    \n",
    "    print(f\"‚úÖ {crypto_name} data loaded: {len(combined_df):,} total rows\")\n",
    "    print(f\"   Date range: {combined_df.index.min()} to {combined_df.index.max()}\")\n",
    "    print()\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Load data for all cryptocurrencies\n",
    "print(\"=\" * 60)\n",
    "print(\"Loading Cryptocurrency Data\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# BTC Data\n",
    "btc_data = load_crypto_data('BTC', 'BTCUSD DATA')\n",
    "\n",
    "# ETH Data\n",
    "eth_data = load_crypto_data('ETH', 'ETHUSD DATA')\n",
    "\n",
    "# SOL Data\n",
    "sol_data = load_crypto_data('SOL', 'SOLUSD DATA')\n",
    "\n",
    "# XRP Data (note: XRP has a nested folder structure)\n",
    "xrp_data = load_crypto_data('XRP', 'XRPUSD DATA')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Data Loading Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Available DataFrames:\")\n",
    "print(f\"  - btc_data: {len(btc_data) if btc_data is not None else 0:,} rows\")\n",
    "print(f\"  - eth_data: {len(eth_data) if eth_data is not None else 0:,} rows\")\n",
    "print(f\"  - sol_data: {len(sol_data) if sol_data is not None else 0:,} rows\")\n",
    "print(f\"  - xrp_data: {len(xrp_data) if xrp_data is not None else 0:,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e6fb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. RESAMPLE TO DAILY CANDLES\n",
    "# ============================================================================\n",
    "\n",
    "def resample_to_daily(df_minute):\n",
    "    \"\"\"\n",
    "    Resample minute-level OHLCV data to daily candles.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_minute : pd.DataFrame\n",
    "        DataFrame with minute-level data, indexed by DateTime\n",
    "        Must have columns: Open, High, Low, Close, Volume\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Daily candles with columns: Open, High, Low, Close, Volume\n",
    "        Indexed by date (date only, no time)\n",
    "    \"\"\"\n",
    "    if df_minute is None or len(df_minute) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Resample to daily\n",
    "    daily = df_minute.resample('D').agg({\n",
    "        'Open': 'first',      # First open of the day\n",
    "        'High': 'max',        # Maximum high of the day\n",
    "        'Low': 'min',         # Minimum low of the day\n",
    "        'Close': 'last',      # Last close of the day\n",
    "        'Volume': 'sum'       # Sum of volume for the day\n",
    "    })\n",
    "    \n",
    "    # Remove days with no data (missing days)\n",
    "    daily = daily.dropna()\n",
    "    \n",
    "    # Normalize index to date only (remove time component)\n",
    "    daily.index = daily.index.normalize()\n",
    "    \n",
    "    return daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faa5e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. DAILY BIAS CLASSIFICATION (10-SCENARIO LOGIC)\n",
    "# ============================================================================\n",
    "\n",
    "def add_rvol_and_volume_label(df, lookback=20):\n",
    "    \"\"\"\n",
    "    Add Relative Volume (RVOL) and volume_label columns to the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with 'Volume' column, indexed by date/time\n",
    "    lookback : int\n",
    "        Number of bars to use for rolling average (default 20)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with added 'rvol' and 'volume_label' columns\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Compute average volume over last N bars\n",
    "    # Use min_periods=lookback so RVOL is NaN if there aren't enough bars\n",
    "    df['avg_vol'] = df['Volume'].rolling(window=lookback, min_periods=lookback).mean()\n",
    "    \n",
    "    # Compute RVOL = current_bar_volume / avg_vol\n",
    "    # Will be NaN if there aren't enough bars for avg_vol\n",
    "    df['rvol'] = df['Volume'] / df['avg_vol']\n",
    "    \n",
    "    # Check if current bar's volume is a local maximum over the last N bars (same as lookback)\n",
    "    # Only check if we have enough history\n",
    "    df['is_local_max'] = False\n",
    "    if len(df) >= lookback:\n",
    "        rolling_max = df['Volume'].rolling(window=lookback, min_periods=lookback).max()\n",
    "        df['is_local_max'] = df['Volume'] == rolling_max\n",
    "    \n",
    "    # Assign volume labels based on RVOL thresholds\n",
    "    # If there's not yet N bars of history, RVOL will be NaN, treat as \"Normal\"\n",
    "    volume_labels = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        rvol = row['rvol']\n",
    "        is_local_max = row['is_local_max']\n",
    "        \n",
    "        # If RVOL is NaN (not enough history), treat as \"Normal\"\n",
    "        if pd.isna(rvol):\n",
    "            volume_labels.append('Normal')\n",
    "        # Ultra-High: rvol >= 3.0 OR current bar's volume is local maximum\n",
    "        elif rvol >= 3.0 or is_local_max:\n",
    "            volume_labels.append('Ultra-High')\n",
    "        # High: 1.5 <= rvol < 3.0\n",
    "        elif rvol >= 1.5:\n",
    "            volume_labels.append('High')\n",
    "        # Normal: 0.75 <= rvol < 1.5\n",
    "        elif rvol >= 0.75:\n",
    "            volume_labels.append('Normal')\n",
    "        # Low: 0.4 <= rvol < 0.75\n",
    "        elif rvol >= 0.4:\n",
    "            volume_labels.append('Low')\n",
    "        # Ultra-Low: rvol < 0.4\n",
    "        else:\n",
    "            volume_labels.append('Ultra-Low')\n",
    "    \n",
    "    df['volume_label'] = volume_labels\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    df = df.drop(columns=['is_local_max'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def map_volume_label_to_scenario_condition(volume_label):\n",
    "    \"\"\"\n",
    "    Map volume_label to the textual conditions used in bias scenarios.\n",
    "    \n",
    "    Translation rules from table:\n",
    "    - \"Above average\" ‚Üí High or Ultra-High\n",
    "    - \"Low to average\" / \"Below average\" ‚Üí Low or Normal\n",
    "    - \"Low\" ‚Üí Low (exact match required)\n",
    "    - \"Ultra-high\" ‚Üí Ultra-High (exact match required)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    volume_label : str\n",
    "        Volume label: 'Ultra-High', 'High', 'Normal', 'Low', or 'Ultra-Low'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with keys: 'above_average', 'low_to_average', 'below_average', 'low', 'ultra_high'\n",
    "        Values are boolean indicating if the condition is met\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'above_average': volume_label in ['High', 'Ultra-High'],  # \"Above average\"\n",
    "        'low_to_average': volume_label in ['Low', 'Normal'],       # \"Low to average\"\n",
    "        'below_average': volume_label in ['Low', 'Normal'],        # \"Below average\"\n",
    "        'low': volume_label == 'Low',                             # \"Low\" (exact)\n",
    "        'ultra_high': volume_label == 'Ultra-High'                 # \"Ultra-high\" (exact)\n",
    "    }\n",
    "\n",
    "\n",
    "def classify_price_volume_relationship(candle_a, candle_b):\n",
    "    \"\"\"\n",
    "    Classify the price-volume relationship from candle A to candle B.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (price_direction, volume_direction, description)\n",
    "        price_direction: 'up', 'down', or 'inside'\n",
    "        volume_direction: 'up', 'down', or 'flat'\n",
    "        description: string describing the relationship\n",
    "    \"\"\"\n",
    "    price_a_to_b = candle_b['Close'] - candle_a['Close']\n",
    "    volume_a_to_b = candle_b['Volume'] - candle_a['Volume']\n",
    "    \n",
    "    # Price direction\n",
    "    if price_a_to_b > 0:\n",
    "        price_dir = 'up'\n",
    "    elif price_a_to_b < 0:\n",
    "        price_dir = 'down'\n",
    "    else:\n",
    "        price_dir = 'inside'\n",
    "    \n",
    "    # Volume direction (using 5% threshold for 'flat')\n",
    "    volume_change_pct = abs(volume_a_to_b / candle_a['Volume']) if candle_a['Volume'] > 0 else 0\n",
    "    if volume_change_pct < 0.05:\n",
    "        volume_dir = 'flat'\n",
    "    elif volume_a_to_b > 0:\n",
    "        volume_dir = 'up'\n",
    "    else:\n",
    "        volume_dir = 'down'\n",
    "    \n",
    "    # Generate description\n",
    "    if price_dir == 'up' and volume_dir == 'up':\n",
    "        desc = 'converging'\n",
    "    elif price_dir == 'up' and (volume_dir == 'down' or volume_dir == 'flat'):\n",
    "        desc = 'diverging'\n",
    "    elif price_dir == 'down' and volume_dir == 'up':\n",
    "        desc = 'converging'\n",
    "    elif price_dir == 'down' and (volume_dir == 'down' or volume_dir == 'flat'):\n",
    "        desc = 'diverging'\n",
    "    else:\n",
    "        desc = 'neutral'\n",
    "    \n",
    "    return price_dir, volume_dir, desc\n",
    "\n",
    "\n",
    "def determine_scenario(candle_a, candle_b):\n",
    "    \"\"\"\n",
    "    Determine which of the 10 scenarios applies based on candle A and B.\n",
    "    \n",
    "    Uses the volume_label column from candle_b (which should be computed using add_rvol_and_volume_label).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    candle_a : pd.Series\n",
    "        Previous day before B (Candle A) with OHLCV data\n",
    "    candle_b : pd.Series\n",
    "        Previous daily candle (Candle B) with OHLCV data and volume_label column\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        Scenario number (1-10), or None if no scenario matches\n",
    "    \"\"\"\n",
    "    pch = candle_a['High']  # Previous Candle High\n",
    "    pcl = candle_a['Low']   # Previous Candle Low\n",
    "    \n",
    "    candle_b_high = candle_b['High']\n",
    "    candle_b_low = candle_b['Low']\n",
    "    candle_b_close = candle_b['Close']\n",
    "    candle_b_open = candle_b['Open']\n",
    "    \n",
    "    # Get volume label from candle_b (must have been computed using add_rvol_and_volume_label)\n",
    "    volume_label = candle_b.get('volume_label', 'Normal')  # Default to 'Normal' if not present\n",
    "    \n",
    "    # Map volume label to scenario conditions\n",
    "    vol_conditions = map_volume_label_to_scenario_condition(volume_label)\n",
    "    \n",
    "    # Determine if candle B has wicks above/below PCH/PCL\n",
    "    wicks_above_pch = candle_b_high > pch\n",
    "    wicks_below_pcl = candle_b_low < pcl\n",
    "    \n",
    "    # Determine if candle B tests PCH/PCL (touches or very close, within 0.1%)\n",
    "    tolerance = (pch - pcl) * 0.001\n",
    "    tests_pch = abs(candle_b_high - pch) <= tolerance or (candle_b_high >= pch and candle_b_low <= pch)\n",
    "    tests_pcl = abs(candle_b_low - pcl) <= tolerance or (candle_b_low <= pcl and candle_b_high >= pcl)\n",
    "    \n",
    "    # Determine if candle B stays inside candle A\n",
    "    stays_inside = candle_b_high <= pch and candle_b_low >= pcl\n",
    "    \n",
    "    # Check if inside bar\n",
    "    is_inside_bar = stays_inside\n",
    "    \n",
    "    # Check if inside bar with long wicks (wicks are significant portion of range)\n",
    "    candle_b_range = candle_b_high - candle_b_low\n",
    "    candle_a_range = pch - pcl\n",
    "    has_long_wicks = False\n",
    "    if is_inside_bar and candle_a_range > 0:\n",
    "        # Long wicks if body is small relative to range, or wicks are large\n",
    "        body_size = abs(candle_b_close - candle_b_open)\n",
    "        if body_size < candle_b_range * 0.3:  # Small body relative to range\n",
    "            has_long_wicks = True\n",
    "    \n",
    "    # Price-volume relationship\n",
    "    price_dir, vol_dir, pv_desc = classify_price_volume_relationship(candle_a, candle_b)\n",
    "    \n",
    "    # Check for new high/low vs A\n",
    "    new_high_vs_a = candle_b_high > pch\n",
    "    new_low_vs_a = candle_b_low < pcl\n",
    "    \n",
    "    # Check scenarios in priority order (more specific conditions first)\n",
    "    # Based on the 10-scenario table with exact volume signature mappings\n",
    "    \n",
    "    # First check inside bar scenarios (mutually exclusive with wicks/tests)\n",
    "    if is_inside_bar:\n",
    "        # SCENARIO 10: Inside bar with long wicks, \"Above average\" volume, high effort little result (churn)\n",
    "        if has_long_wicks and vol_conditions['above_average']:\n",
    "            return 10\n",
    "        # SCENARIO 9: Inside bar, \"Below average\" volume, range and volume contraction\n",
    "        if not has_long_wicks and vol_conditions['below_average']:\n",
    "            return 9\n",
    "    \n",
    "    # Check wicks scenarios before test scenarios (wicks are more specific than tests)\n",
    "    # SCENARIO 3: Wicks above PCH, closes back below PCH, \"Above average\" volume, new high rejected on heavy volume\n",
    "    if wicks_above_pch and candle_b_close < pch and vol_conditions['above_average'] and new_high_vs_a:\n",
    "        return 3\n",
    "    \n",
    "    # SCENARIO 4: Wicks above PCH, closes back below PCH, \"Below average\" volume, attempt higher on low volume\n",
    "    if wicks_above_pch and candle_b_close < pch and vol_conditions['below_average']:\n",
    "        return 4\n",
    "    \n",
    "    # SCENARIO 7: Wicks below PCL, closes back above PCL, \"Above average\" volume, new low rejected on heavy volume\n",
    "    if wicks_below_pcl and candle_b_close > pcl and vol_conditions['above_average'] and new_low_vs_a:\n",
    "        return 7\n",
    "    \n",
    "    # SCENARIO 8: Wicks below PCL, closes back above PCL, \"Below average\" volume, attempt lower on low volume\n",
    "    if wicks_below_pcl and candle_b_close > pcl and vol_conditions['below_average']:\n",
    "        return 8\n",
    "    \n",
    "    # Now check test scenarios (exclude cases already caught by wicks)\n",
    "    # SCENARIO 1: Tests PCH (but doesn't wick above), closes above PCH, \"Above average\" volume, price up volume up (converging)\n",
    "    if not wicks_above_pch and tests_pch and candle_b_close > pch and vol_conditions['above_average'] and pv_desc == 'converging' and price_dir == 'up':\n",
    "        return 1\n",
    "    \n",
    "    # SCENARIO 2: Tests PCH (but doesn't wick above), closes above PCH, \"Low to average\" volume, price up volume down/flat (diverging)\n",
    "    if not wicks_above_pch and tests_pch and candle_b_close > pch and vol_conditions['low_to_average'] and pv_desc == 'diverging' and price_dir == 'up':\n",
    "        return 2\n",
    "    \n",
    "    # SCENARIO 5: Tests PCL (but doesn't wick below), closes below PCL, \"Above average\" volume, price down volume up (converging)\n",
    "    if not wicks_below_pcl and tests_pcl and candle_b_close < pcl and vol_conditions['above_average'] and pv_desc == 'converging' and price_dir == 'down':\n",
    "        return 5\n",
    "    \n",
    "    # SCENARIO 6: Tests PCL (but doesn't wick below), closes below PCL, \"Low to average\" volume, price down volume down/flat (diverging)\n",
    "    if not wicks_below_pcl and tests_pcl and candle_b_close < pcl and vol_conditions['low_to_average'] and pv_desc == 'diverging' and price_dir == 'down':\n",
    "        return 6\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def scenario_to_bias(scenario):\n",
    "    \"\"\"\n",
    "    Map scenario number to bias label.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        'bullish', 'bearish', or 'neutral'\n",
    "    \"\"\"\n",
    "    if scenario is None:\n",
    "        return 'neutral'\n",
    "    \n",
    "    # Scenario 1: Strong bullish continuation\n",
    "    if scenario == 1:\n",
    "        return 'bullish'\n",
    "    \n",
    "    # Scenario 2: Weak/potential bull trap; bearish\n",
    "    if scenario == 2:\n",
    "        return 'bearish'\n",
    "    \n",
    "    # Scenario 3: Bearish reversal bias\n",
    "    if scenario == 3:\n",
    "        return 'bearish'\n",
    "    \n",
    "    # Scenario 4: Bearish bias\n",
    "    if scenario == 4:\n",
    "        return 'bearish'\n",
    "    \n",
    "    # Scenario 5: Strong bearish continuation\n",
    "    if scenario == 5:\n",
    "        return 'bearish'\n",
    "    \n",
    "    # Scenario 6: Weak/potential bear trap; bullish\n",
    "    if scenario == 6:\n",
    "        return 'bullish'\n",
    "    \n",
    "    # Scenario 7: Bullish reversal bias\n",
    "    if scenario == 7:\n",
    "        return 'bullish'\n",
    "    \n",
    "    # Scenario 8: Bullish bias\n",
    "    if scenario == 8:\n",
    "        return 'bullish'\n",
    "    \n",
    "    # Scenario 9: Neutral bias\n",
    "    if scenario == 9:\n",
    "        return 'neutral'\n",
    "    \n",
    "    # Scenario 10: Neutral bias (wait for clear break)\n",
    "    if scenario == 10:\n",
    "        return 'neutral'\n",
    "    \n",
    "    return 'neutral'\n",
    "\n",
    "\n",
    "def classify_daily_bias(df_daily, lookback=20):\n",
    "    \"\"\"\n",
    "    Classify daily bias for all eligible days in the daily DataFrame.\n",
    "    \n",
    "    Uses the RVOL framework to classify volume levels before determining bias scenarios.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_daily : pd.DataFrame\n",
    "        Daily candles with columns: Open, High, Low, Close, Volume\n",
    "        Indexed by date\n",
    "    lookback : int\n",
    "        Number of bars to use for RVOL calculation (default 20 days)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns: date, bias, scenario\n",
    "        Only includes days where bias could be determined (starting from 3rd day)\n",
    "    \"\"\"\n",
    "    if df_daily is None or len(df_daily) < 3:\n",
    "        return pd.DataFrame(columns=['date', 'bias', 'scenario'])\n",
    "    \n",
    "    # Add RVOL and volume_label columns using the RVOL framework\n",
    "    df_daily = add_rvol_and_volume_label(df_daily, lookback=lookback)\n",
    "    \n",
    "    # Store results\n",
    "    results = []\n",
    "    \n",
    "    # Iterate starting from the 3rd day (index 2)\n",
    "    # Candle A = day i-2, Candle B = day i-1, Candle C = day i\n",
    "    for i in range(2, len(df_daily)):\n",
    "        candle_a = df_daily.iloc[i-2]  # Previous day before B\n",
    "        candle_b = df_daily.iloc[i-1]  # Previous daily candle\n",
    "        candle_c_date = df_daily.index[i]  # Current day (C)\n",
    "        \n",
    "        # Determine scenario (now uses volume_label from candle_b)\n",
    "        scenario = determine_scenario(candle_a, candle_b)\n",
    "        \n",
    "        # Map scenario to bias\n",
    "        bias = scenario_to_bias(scenario)\n",
    "        \n",
    "        results.append({\n",
    "            'date': candle_c_date,\n",
    "            'bias': bias,\n",
    "            'scenario': scenario\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddff1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. ITERATE OVER FULL HISTORY AND COMPUTE BIASES\n",
    "# ============================================================================\n",
    "\n",
    "def compute_all_biases(data_dict, lookback=20):\n",
    "    \"\"\"\n",
    "    Compute daily biases for all symbols using the RVOL framework.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary mapping symbol names to minute-level DataFrames\n",
    "        e.g., {'BTC': btc_data, 'ETH': eth_data, ...}\n",
    "    lookback : int\n",
    "        Number of bars to use for RVOL calculation (default 20)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns: date, symbol, bias, scenario\n",
    "    \"\"\"\n",
    "    all_biases = []\n",
    "    \n",
    "    for symbol, df_minute in data_dict.items():\n",
    "        if df_minute is None or len(df_minute) == 0:\n",
    "            print(f\"‚ö†Ô∏è Skipping {symbol}: no data available\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"üìà Processing {symbol}...\")\n",
    "        \n",
    "        # Resample to daily\n",
    "        df_daily = resample_to_daily(df_minute)\n",
    "        \n",
    "        if df_daily is None or len(df_daily) < 3:\n",
    "            print(f\"   ‚ö†Ô∏è {symbol}: insufficient data for bias calculation (need at least 3 days)\")\n",
    "            continue\n",
    "        \n",
    "        # Classify biases (now uses RVOL framework)\n",
    "        bias_df = classify_daily_bias(df_daily, lookback=lookback)\n",
    "        \n",
    "        # Add symbol column\n",
    "        bias_df['symbol'] = symbol\n",
    "        \n",
    "        # Reorder columns\n",
    "        bias_df = bias_df[['date', 'symbol', 'bias', 'scenario']]\n",
    "        \n",
    "        all_biases.append(bias_df)\n",
    "        print(f\"   ‚úÖ {symbol}: {len(bias_df):,} days with bias classifications\")\n",
    "    \n",
    "    if not all_biases:\n",
    "        return pd.DataFrame(columns=['date', 'symbol', 'bias', 'scenario'])\n",
    "    \n",
    "    # Combine all results\n",
    "    combined_bias_df = pd.concat(all_biases, ignore_index=True)\n",
    "    \n",
    "    return combined_bias_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cbc2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. PRODUCE SUMMARY COUNTS\n",
    "# ============================================================================\n",
    "\n",
    "def summarize_bias_counts(bias_df):\n",
    "    \"\"\"\n",
    "    Produce summary counts of bullish, bearish, and neutral biases for each symbol.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    bias_df : pd.DataFrame\n",
    "        DataFrame with columns: date, symbol, bias, scenario\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Summary DataFrame with columns: symbol, bullish, bearish, neutral, total\n",
    "    dict\n",
    "        Dictionary mapping symbol to counts dict\n",
    "    \"\"\"\n",
    "    if bias_df is None or len(bias_df) == 0:\n",
    "        print(\"No bias data available for summary.\")\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    summary_list = []\n",
    "    summary_dict = {}\n",
    "    \n",
    "    for symbol in bias_df['symbol'].unique():\n",
    "        symbol_data = bias_df[bias_df['symbol'] == symbol]\n",
    "        \n",
    "        bullish_count = len(symbol_data[symbol_data['bias'] == 'bullish'])\n",
    "        bearish_count = len(symbol_data[symbol_data['bias'] == 'bearish'])\n",
    "        neutral_count = len(symbol_data[symbol_data['bias'] == 'neutral'])\n",
    "        total_count = len(symbol_data)\n",
    "        \n",
    "        summary_list.append({\n",
    "            'symbol': symbol,\n",
    "            'bullish': bullish_count,\n",
    "            'bearish': bearish_count,\n",
    "            'neutral': neutral_count,\n",
    "            'total': total_count\n",
    "        })\n",
    "        \n",
    "        summary_dict[symbol] = {\n",
    "            'bullish': bullish_count,\n",
    "            'bearish': bearish_count,\n",
    "            'neutral': neutral_count,\n",
    "            'total': total_count\n",
    "        }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_list)\n",
    "    \n",
    "    # Calculate totals across all symbols\n",
    "    total_bullish = summary_df['bullish'].sum()\n",
    "    total_bearish = summary_df['bearish'].sum()\n",
    "    total_neutral = summary_df['neutral'].sum()\n",
    "    total_days = summary_df['total'].sum()\n",
    "    \n",
    "    # Add totals row to the DataFrame\n",
    "    totals_row = pd.DataFrame([{\n",
    "        'symbol': 'TOTAL',\n",
    "        'bullish': total_bullish,\n",
    "        'bearish': total_bearish,\n",
    "        'neutral': total_neutral,\n",
    "        'total': total_days\n",
    "    }])\n",
    "    summary_df = pd.concat([summary_df, totals_row], ignore_index=True)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Daily Bias Summary by Symbol\")\n",
    "    print(\"=\" * 60)\n",
    "    for _, row in summary_df.iterrows():\n",
    "        print(f\"{row['symbol']} ‚Äì bullish: {row['bullish']:,}, \"\n",
    "              f\"bearish: {row['bearish']:,}, \"\n",
    "              f\"neutral: {row['neutral']:,} \"\n",
    "              f\"(total: {row['total']:,} days)\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    return summary_df, summary_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa29483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Resampling to Daily Candles\n",
      "============================================================\n",
      "\n",
      "‚úÖ BTC: 2,539 daily candles\n",
      "‚úÖ ETH: 2,539 daily candles\n",
      "‚úÖ SOL: 1,078 daily candles\n",
      "‚úÖ XRP: 2,540 daily candles\n",
      "\n",
      "============================================================\n",
      "Computing Daily Biases\n",
      "============================================================\n",
      "\n",
      "üìà Processing BTC...\n",
      "   ‚úÖ BTC: 2,537 days with bias classifications\n",
      "üìà Processing ETH...\n",
      "   ‚úÖ ETH: 2,537 days with bias classifications\n",
      "üìà Processing SOL...\n",
      "   ‚úÖ SOL: 1,076 days with bias classifications\n",
      "üìà Processing XRP...\n",
      "   ‚úÖ XRP: 2,538 days with bias classifications\n",
      "\n",
      "============================================================\n",
      "Bias Computation Complete!\n",
      "============================================================\n",
      "Total bias classifications: 8,688\n",
      "\n",
      "Sample of bias results:\n",
      "                       date symbol     bias  scenario\n",
      "0 2019-01-03 00:00:00+00:00    BTC  neutral       NaN\n",
      "1 2019-01-04 00:00:00+00:00    BTC  bullish       8.0\n",
      "2 2019-01-05 00:00:00+00:00    BTC  bullish       8.0\n",
      "3 2019-01-06 00:00:00+00:00    BTC  bearish       4.0\n",
      "4 2019-01-07 00:00:00+00:00    BTC  bullish       8.0\n",
      "5 2019-01-08 00:00:00+00:00    BTC  neutral       NaN\n",
      "6 2019-01-09 00:00:00+00:00    BTC  bearish       4.0\n",
      "7 2019-01-10 00:00:00+00:00    BTC  neutral       NaN\n",
      "8 2019-01-11 00:00:00+00:00    BTC  neutral       NaN\n",
      "9 2019-01-12 00:00:00+00:00    BTC  bullish       8.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXECUTE: Resample to daily and compute biases\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Resampling to Daily Candles\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Prepare data dictionary\n",
    "crypto_data = {\n",
    "    'BTC': btc_data,\n",
    "    'ETH': eth_data,\n",
    "    'SOL': sol_data,\n",
    "    'XRP': xrp_data\n",
    "}\n",
    "\n",
    "# Resample each to daily\n",
    "daily_data = {}\n",
    "for symbol, df_minute in crypto_data.items():\n",
    "    if df_minute is not None:\n",
    "        daily_data[symbol] = resample_to_daily(df_minute)\n",
    "        if daily_data[symbol] is not None:\n",
    "            print(f\"‚úÖ {symbol}: {len(daily_data[symbol]):,} daily candles\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {symbol}: failed to resample\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {symbol}: no minute data available\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Computing Daily Biases\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Compute all biases (using RVOL framework with default lookback=20)\n",
    "bias_results = compute_all_biases(crypto_data, lookback=20)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Bias Computation Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total bias classifications: {len(bias_results):,}\")\n",
    "print()\n",
    "\n",
    "# Display first few rows\n",
    "if len(bias_results) > 0:\n",
    "    print(\"Sample of bias results:\")\n",
    "    print(bias_results.head(10))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "344c4e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Daily Bias Summary by Symbol\n",
      "============================================================\n",
      "BTC ‚Äì bullish: 455, bearish: 572, neutral: 1,510 (total: 2,537 days)\n",
      "ETH ‚Äì bullish: 458, bearish: 563, neutral: 1,516 (total: 2,537 days)\n",
      "SOL ‚Äì bullish: 178, bearish: 249, neutral: 649 (total: 1,076 days)\n",
      "XRP ‚Äì bullish: 458, bearish: 536, neutral: 1,544 (total: 2,538 days)\n",
      "TOTAL ‚Äì bullish: 1,549, bearish: 1,920, neutral: 5,219 (total: 8,688 days)\n",
      "============================================================\n",
      "\n",
      "Summary DataFrame:\n",
      "  symbol  bullish  bearish  neutral  total\n",
      "0    BTC      455      572     1510   2537\n",
      "1    ETH      458      563     1516   2537\n",
      "2    SOL      178      249      649   1076\n",
      "3    XRP      458      536     1544   2538\n",
      "4  TOTAL     1549     1920     5219   8688\n",
      "\n",
      "Summary Dictionary (for programmatic access):\n",
      "  BTC: {'bullish': 455, 'bearish': 572, 'neutral': 1510, 'total': 2537}\n",
      "  ETH: {'bullish': 458, 'bearish': 563, 'neutral': 1516, 'total': 2537}\n",
      "  SOL: {'bullish': 178, 'bearish': 249, 'neutral': 649, 'total': 1076}\n",
      "  XRP: {'bullish': 458, 'bearish': 536, 'neutral': 1544, 'total': 2538}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXECUTE: Produce summary counts\n",
    "# ============================================================================\n",
    "\n",
    "# Generate summary\n",
    "summary_df, summary_dict = summarize_bias_counts(bias_results)\n",
    "\n",
    "# Display summary DataFrame\n",
    "if len(summary_df) > 0:\n",
    "    print(\"Summary DataFrame:\")\n",
    "    print(summary_df)\n",
    "    print()\n",
    "    \n",
    "    # Also available as dictionary for programmatic access\n",
    "    print(\"Summary Dictionary (for programmatic access):\")\n",
    "    for symbol, counts in summary_dict.items():\n",
    "        print(f\"  {symbol}: {counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c54432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Bias Data Exported to CSV\n",
      "============================================================\n",
      "‚úÖ Exported 8,688 rows to: calendar-app/public/bias-data.csv\n",
      "   Columns: date, symbol, bias, scenario\n",
      "   Symbols: BTC, ETH, SOL, XRP\n",
      "\n",
      "To use the React calendar app:\n",
      "1. Navigate to calendar-app/ directory\n",
      "2. Run: npm install (if not done already)\n",
      "3. Update src/App.tsx to include '/bias-data.csv' in csvFiles array\n",
      "4. Run: npm run dev\n",
      "5. Open browser to the URL shown (usually http://localhost:5173)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXPORT BIAS DATA TO CSV FOR REACT CALENDAR APP\n",
    "# ============================================================================\n",
    "\n",
    "# Export bias_results to CSV for the React calendar app\n",
    "if 'bias_results' in globals() and len(bias_results) > 0:\n",
    "    # Format date column for CSV (YYYY-MM-DD format)\n",
    "    export_df = bias_results.copy()\n",
    "    \n",
    "    # Convert date to string format if it's datetime\n",
    "    if pd.api.types.is_datetime64_any_dtype(export_df['date']):\n",
    "        export_df['date'] = export_df['date'].dt.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        export_df['date'] = pd.to_datetime(export_df['date']).dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Ensure columns are in the right order: date, symbol, bias, scenario\n",
    "    export_df = export_df[['date', 'symbol', 'bias', 'scenario']]\n",
    "    \n",
    "    # Export to CSV in the calendar-app public folder\n",
    "    csv_path = 'calendar-app/public/bias-data.csv'\n",
    "    export_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Bias Data Exported to CSV\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Exported {len(export_df):,} rows to: {csv_path}\")\n",
    "    print(f\"   Columns: {', '.join(export_df.columns.tolist())}\")\n",
    "    print(f\"   Symbols: {', '.join(sorted(export_df['symbol'].unique()))}\")\n",
    "    print()\n",
    "    print(\"To use the React calendar app:\")\n",
    "    print(\"1. Navigate to calendar-app/ directory\")\n",
    "    print(\"2. Run: npm install (if not done already)\")\n",
    "    print(\"3. Update src/App.tsx to include '/bias-data.csv' in csvFiles array\")\n",
    "    print(\"4. Run: npm run dev\")\n",
    "    print(\"5. Open browser to the URL shown (usually http://localhost:5173)\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No bias_results available. Please run the bias computation cells first.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f075d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating interactive calendar widget...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02114895201b49d89c163cd9aab26abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Symbol:', layout=Layout(width='200px'), options=('BTC', 'E‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# INTERACTIVE CALENDAR WIDGET FOR JUPYTER NOTEBOOK\n",
    "# ============================================================================\n",
    "# Note: Requires ipywidgets - install with: pip install ipywidgets\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "    import calendar\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    IPYWIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è ipywidgets not installed. Install with: pip install ipywidgets\")\n",
    "    print(\"   Then restart the kernel and run this cell again.\")\n",
    "    IPYWIDGETS_AVAILABLE = False\n",
    "\n",
    "def create_calendar_widget(bias_df):\n",
    "    \"\"\"\n",
    "    Create an interactive calendar widget for Jupyter notebook.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    bias_df : pd.DataFrame\n",
    "        DataFrame with columns: date, symbol, bias, scenario (and any other columns)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    ipywidgets.Widget\n",
    "        Interactive calendar widget\n",
    "    \"\"\"\n",
    "    if bias_df is None or len(bias_df) == 0:\n",
    "        return widgets.HTML(\"<p>No bias data available</p>\")\n",
    "    \n",
    "    # Ensure date column is datetime\n",
    "    bias_df = bias_df.copy()\n",
    "    if not pd.api.types.is_datetime64_any_dtype(bias_df['date']):\n",
    "        bias_df['date'] = pd.to_datetime(bias_df['date'])\n",
    "    \n",
    "    # Get unique symbols\n",
    "    symbols = sorted(bias_df['symbol'].unique().tolist())\n",
    "    \n",
    "    # Create symbol selector\n",
    "    symbol_dropdown = widgets.Dropdown(\n",
    "        options=symbols,\n",
    "        value=symbols[0] if symbols else None,\n",
    "        description='Symbol:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    # Helper function to get date range for a symbol\n",
    "    def get_symbol_date_range(symbol):\n",
    "        \"\"\"Get min and max dates for a specific symbol\"\"\"\n",
    "        symbol_data = bias_df[bias_df['symbol'] == symbol]\n",
    "        if len(symbol_data) == 0:\n",
    "            # Fallback to full dataset range\n",
    "            min_date = bias_df['date'].min()\n",
    "            max_date = bias_df['date'].max()\n",
    "        else:\n",
    "            min_date = symbol_data['date'].min()\n",
    "            max_date = symbol_data['date'].max()\n",
    "        return min_date, max_date\n",
    "    \n",
    "    # Initialize with first symbol's date range\n",
    "    initial_symbol = symbols[0] if symbols else None\n",
    "    if initial_symbol:\n",
    "        min_date, max_date = get_symbol_date_range(initial_symbol)\n",
    "        year_options = list(range(min_date.year, max_date.year + 1))\n",
    "        initial_year = min_date.year\n",
    "        initial_month = min_date.month\n",
    "    else:\n",
    "        # Fallback\n",
    "        min_date = bias_df['date'].min()\n",
    "        max_date = bias_df['date'].max()\n",
    "        year_options = list(range(min_date.year, max_date.year + 1))\n",
    "        initial_year = min_date.year\n",
    "        initial_month = min_date.month\n",
    "    \n",
    "    # Create month/year selectors\n",
    "    year_dropdown = widgets.Dropdown(\n",
    "        options=year_options,\n",
    "        value=initial_year,\n",
    "        description='Year:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='150px')\n",
    "    )\n",
    "    \n",
    "    month_dropdown = widgets.Dropdown(\n",
    "        options=[(calendar.month_name[i], i) for i in range(1, 13)],\n",
    "        value=initial_month,\n",
    "        description='Month:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    # Navigation buttons\n",
    "    prev_button = widgets.Button(description='‚Üê Prev', layout=widgets.Layout(width='100px'))\n",
    "    next_button = widgets.Button(description='Next ‚Üí', layout=widgets.Layout(width='100px'))\n",
    "    \n",
    "    # Output area for calendar and details\n",
    "    calendar_output = widgets.Output()\n",
    "    details_output = widgets.Output()\n",
    "    \n",
    "    # Selected date info\n",
    "    selected_date_info = widgets.HTML(\"\")\n",
    "    \n",
    "    def get_bias_color(bias):\n",
    "        \"\"\"Get color for bias type\"\"\"\n",
    "        if bias == 'bullish':\n",
    "            return '#4caf50'  # Green\n",
    "        elif bias == 'bearish':\n",
    "            return '#f44336'  # Red\n",
    "        else:\n",
    "            return '#e0e0e0'  # Grey\n",
    "    \n",
    "    \n",
    "    def show_date_details(date_str, symbol, bias, scenario):\n",
    "        \"\"\"Display details for selected date\"\"\"\n",
    "        # Find the full row data\n",
    "        symbol_data = bias_df[bias_df['symbol'] == symbol].copy()\n",
    "        date_obj = pd.to_datetime(date_str)\n",
    "        date_key = date_obj.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Try to find matching row\n",
    "        matching_rows = symbol_data[symbol_data['date'].dt.strftime('%Y-%m-%d') == date_key]\n",
    "        \n",
    "        if len(matching_rows) > 0:\n",
    "            row = matching_rows.iloc[0]\n",
    "            details_html = f\"\"\"\n",
    "            <div style=\"background: #f8f9fa; border-radius: 12px; padding: 20px; margin-top: 20px; border: 2px solid #e0e0e0;\">\n",
    "                <h3 style=\"color: #333; margin-bottom: 15px; font-size: 18px;\">Daily Bias Details</h3>\n",
    "                <div style=\"display: flex; flex-direction: column; gap: 12px;\">\n",
    "                    <div style=\"display: flex; justify-content: space-between;\">\n",
    "                        <span style=\"font-weight: 600; color: #666;\">Symbol:</span>\n",
    "                        <span style=\"color: #333;\">{symbol}</span>\n",
    "                    </div>\n",
    "                    <div style=\"display: flex; justify-content: space-between;\">\n",
    "                        <span style=\"font-weight: 600; color: #666;\">Date:</span>\n",
    "                        <span style=\"color: #333;\">{date_obj.strftime('%B %d, %Y')}</span>\n",
    "                    </div>\n",
    "                    <div style=\"display: flex; justify-content: space-between;\">\n",
    "                        <span style=\"font-weight: 600; color: #666;\">Bias:</span>\n",
    "                        <span style=\"background-color: {get_bias_color(bias)}; color: white; padding: 4px 12px; border-radius: 12px; font-weight: 600; font-size: 12px; text-transform: uppercase;\">\n",
    "                            {bias.upper()}\n",
    "                        </span>\n",
    "                    </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Add other columns\n",
    "            excluded_cols = ['symbol', 'date', 'bias']\n",
    "            has_extra = False\n",
    "            for col in row.index:\n",
    "                if col not in excluded_cols and pd.notna(row[col]):\n",
    "                    has_extra = True\n",
    "                    value = row[col]\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        value = f\"{value:,.2f}\" if isinstance(value, float) else f\"{value:,}\"\n",
    "                    details_html += f\"\"\"\n",
    "                    <div style=\"display: flex; justify-content: space-between;\">\n",
    "                        <span style=\"font-weight: 600; color: #666;\">{col.capitalize()}:</span>\n",
    "                        <span style=\"color: #333;\">{value}</span>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "            \n",
    "            details_html += \"\"\"\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        else:\n",
    "            details_html = f\"\"\"\n",
    "            <div style=\"background: #f8f9fa; border-radius: 12px; padding: 20px; margin-top: 20px; border: 2px solid #e0e0e0;\">\n",
    "                <h3 style=\"color: #333; margin-bottom: 15px; font-size: 18px;\">Daily Bias Details</h3>\n",
    "                <div style=\"color: #999; font-style: italic; text-align: center; padding: 20px;\">\n",
    "                    No bias data available for this date.\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        selected_date_info.value = details_html\n",
    "    \n",
    "    \n",
    "    def update_year_month_options(symbol):\n",
    "        \"\"\"Update year and month dropdown options based on selected symbol\"\"\"\n",
    "        min_date, max_date = get_symbol_date_range(symbol)\n",
    "        year_options = list(range(min_date.year, max_date.year + 1))\n",
    "        \n",
    "        # Update year dropdown options\n",
    "        year_dropdown.options = year_options\n",
    "        \n",
    "        # Ensure current year value is valid\n",
    "        current_year = year_dropdown.value\n",
    "        if current_year not in year_options:\n",
    "            year_dropdown.value = min_date.year\n",
    "            month_dropdown.value = min_date.month\n",
    "        else:\n",
    "            # If year is valid, check if month needs adjustment\n",
    "            # If we're at the start year, ensure month is >= min_date.month\n",
    "            if current_year == min_date.year and month_dropdown.value < min_date.month:\n",
    "                month_dropdown.value = min_date.month\n",
    "            # If we're at the end year, ensure month is <= max_date.month\n",
    "            if current_year == max_date.year and month_dropdown.value > max_date.month:\n",
    "                month_dropdown.value = max_date.month\n",
    "    \n",
    "    def navigate_month(direction):\n",
    "        \"\"\"Navigate to previous/next month\"\"\"\n",
    "        year = year_dropdown.value\n",
    "        month = month_dropdown.value\n",
    "        \n",
    "        # Get current symbol's date range to check bounds\n",
    "        symbol = symbol_dropdown.value\n",
    "        min_date, max_date = get_symbol_date_range(symbol)\n",
    "        \n",
    "        if direction == 'prev':\n",
    "            if month == 1:\n",
    "                year -= 1\n",
    "                month = 12\n",
    "            else:\n",
    "                month -= 1\n",
    "        else:  # next\n",
    "            if month == 12:\n",
    "                year += 1\n",
    "                month = 1\n",
    "            else:\n",
    "                month += 1\n",
    "        \n",
    "        # Check bounds - make target_date timezone-aware to match min_date/max_date\n",
    "        target_date = datetime(year, month, 1)\n",
    "        # Convert to timezone-aware if min_date is timezone-aware\n",
    "        if hasattr(min_date, 'tz') and min_date.tz is not None:\n",
    "            target_date = pd.Timestamp(target_date, tz=min_date.tz)\n",
    "        elif isinstance(min_date, pd.Timestamp) and min_date.tz is not None:\n",
    "            target_date = pd.Timestamp(target_date, tz=min_date.tz)\n",
    "        \n",
    "        if target_date < min_date or target_date > max_date:\n",
    "            return  # Don't navigate outside data range\n",
    "        \n",
    "        # Update dropdowns only if the new values are valid\n",
    "        if year in year_dropdown.options:\n",
    "            year_dropdown.value = year\n",
    "        month_dropdown.value = month\n",
    "        update_calendar()\n",
    "    \n",
    "    def on_symbol_change(change):\n",
    "        \"\"\"Handle symbol change - update year/month options and calendar\"\"\"\n",
    "        symbol = change['new']\n",
    "        update_year_month_options(symbol)\n",
    "        update_calendar()\n",
    "    \n",
    "    \n",
    "    def create_clickable_calendar():\n",
    "        \"\"\"Create calendar with clickable dates that update details\"\"\"\n",
    "        symbol = symbol_dropdown.value\n",
    "        year = year_dropdown.value\n",
    "        month = month_dropdown.value\n",
    "        \n",
    "        symbol_data = bias_df[bias_df['symbol'] == symbol].copy()\n",
    "        date_map = {}\n",
    "        for _, row in symbol_data.iterrows():\n",
    "            date_key = row['date'].strftime('%Y-%m-%d')\n",
    "            date_map[date_key] = row.to_dict()\n",
    "        \n",
    "        first_day = datetime(year, month, 1)\n",
    "        first_weekday = first_day.weekday()\n",
    "        days_in_month = calendar.monthrange(year, month)[1]\n",
    "        \n",
    "        # Generate calendar with click handlers that directly update the details\n",
    "        calendar_html = f\"\"\"\n",
    "        \n",
    "        <style>\n",
    "            .calendar-container {\n",
    "                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\n",
    "                max-width: 700px;\n",
    "                margin: 20px auto;\n",
    "                background: white;\n",
    "                border-radius: 12px;\n",
    "                padding: 20px;\n",
    "                box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .calendar-header {\n",
    "                text-align: center;\n",
    "                font-size: 20px;\n",
    "                font-weight: 600;\n",
    "                margin-bottom: 15px;\n",
    "                color: #333;\n",
    "            }\n",
    "            .calendar-weekdays {\n",
    "                display: grid !important;\n",
    "                grid-template-columns: repeat(7, 1fr) !important;\n",
    "                gap: 5px;\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .weekday {\n",
    "                text-align: center;\n",
    "                font-weight: 600;\n",
    "                color: #666;\n",
    "                font-size: 12px;\n",
    "                padding: 8px 0;\n",
    "            }\n",
    "            .calendar-grid {\n",
    "                display: grid !important;\n",
    "                grid-template-columns: repeat(7, 1fr) !important;\n",
    "                grid-auto-rows: minmax(40px, auto);\n",
    "                gap: 5px;\n",
    "                width: 100%;\n",
    "                max-width: 100%;\n",
    "            }\n",
    "            .calendar-day {\n",
    "                aspect-ratio: 1;\n",
    "                min-height: 40px;\n",
    "                min-width: 40px;\n",
    "                display: flex;\n",
    "                align-items: center;\n",
    "                justify-content: center;\n",
    "                border-radius: 8px;\n",
    "                font-size: 14px;\n",
    "                font-weight: 500;\n",
    "                cursor: pointer;\n",
    "                transition: all 0.2s;\n",
    "                border: 2px solid transparent;\n",
    "                color: #333;\n",
    "                box-sizing: border-box;\n",
    "            }\n",
    "            .calendar-day.empty {\n",
    "                background: transparent;\n",
    "                cursor: default;\n",
    "            }\n",
    "            .calendar-day.has-data:hover {\n",
    "                transform: scale(1.1);\n",
    "                box-shadow: 0 2px 8px rgba(0,0,0,0.2);\n",
    "                z-index: 10;\n",
    "            }\n",
    "            .calendar-day.selected {\n",
    "                border-color: #667eea;\n",
    "                border-width: 3px;\n",
    "                transform: scale(1.1);\n",
    "            }\n",
    "        </style>\n",
    "        <div class=\"calendar-container\">\n",
    "            <div class=\"calendar-header\">{calendar.month_name[month]} {year}</div>\n",
    "            <div class=\"calendar-weekdays\">\n",
    "                <div class=\"weekday\">Mo</div><div class=\"weekday\">Tu</div><div class=\"weekday\">We</div>\n",
    "                <div class=\"weekday\">Th</div><div class=\"weekday\">Fr</div><div class=\"weekday\">Sa</div><div class=\"weekday\">Su</div>\n",
    "            </div>\n",
    "            <div class=\"calendar-grid\">\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(first_weekday):\n",
    "            calendar_html += '<div class=\"calendar-day empty\"></div>'\n",
    "        \n",
    "        for day in range(1, days_in_month + 1):\n",
    "            date = datetime(year, month, day)\n",
    "            date_key = date.strftime('%Y-%m-%d')\n",
    "            bias_data = date_map.get(date_key)\n",
    "            \n",
    "            if bias_data:\n",
    "                bias = bias_data.get('bias', 'neutral')\n",
    "                color = get_bias_color(bias)\n",
    "                # Create inline onclick that updates the details div\n",
    "                row_dict = bias_data\n",
    "                details_json = str(row_dict).replace(\"'\", \"\\\\'\")\n",
    "                calendar_html += f'''\n",
    "                <div class=\"calendar-day has-data\" \n",
    "                     style=\"background-color: {color}; color: white;\"\n",
    "                     onclick=\"updateDetails_{symbol}_{date_key.replace('-', '_')}()\">\n",
    "                    {day}\n",
    "                </div>\n",
    "                <script>\n",
    "                    function updateDetails_{symbol}_{date_key.replace('-', '_')}() {{\n",
    "                        document.querySelectorAll('.calendar-day').forEach(el => el.classList.remove('selected'));\n",
    "                        event.target.classList.add('selected');\n",
    "                        var detailsDiv = document.getElementById('date-details-{symbol}');\n",
    "                        if (detailsDiv) {{\n",
    "                            var rowData = {row_dict};\n",
    "                            var html = '<div style=\"background: #f8f9fa; border-radius: 12px; padding: 20px; margin-top: 20px; border: 2px solid #e0e0e0;\"><h3 style=\"color: #333; margin-bottom: 15px;\">Daily Bias Details</h3>';\n",
    "                            html += '<div style=\"display: flex; flex-direction: column; gap: 12px;\">';\n",
    "                            html += '<div style=\"display: flex; justify-content: space-between;\"><span style=\"font-weight: 600; color: #666;\">Symbol:</span><span>' + '{symbol}' + '</span></div>';\n",
    "                            html += '<div style=\"display: flex; justify-content: space-between;\"><span style=\"font-weight: 600; color: #666;\">Date:</span><span>' + '{date.strftime(\"%B %d, %Y\")}' + '</span></div>';\n",
    "                            html += '<div style=\"display: flex; justify-content: space-between;\"><span style=\"font-weight: 600; color: #666;\">Bias:</span><span style=\"background-color: {color}; color: white; padding: 4px 12px; border-radius: 12px; font-weight: 600; font-size: 12px; text-transform: uppercase;\">' + '{bias.upper()}' + '</span></div>';\n",
    "                            if (rowData.scenario !== undefined && rowData.scenario !== null && !isNaN(rowData.scenario)) {{\n",
    "                                html += '<div style=\"display: flex; justify-content: space-between;\"><span style=\"font-weight: 600; color: #666;\">Scenario:</span><span>' + rowData.scenario + '</span></div>';\n",
    "                            }}\n",
    "                            html += '</div></div>';\n",
    "                            detailsDiv.innerHTML = html;\n",
    "                        }}\n",
    "                    }}\n",
    "                </script>\n",
    "                '''\n",
    "            else:\n",
    "                calendar_html += f'<div class=\"calendar-day\" style=\"background-color: #e0e0e0; color: #666;\">{day}</div>'\n",
    "        \n",
    "        calendar_html += '</div></div>'\n",
    "        return calendar_html\n",
    "    \n",
    "    \n",
    "    def update_calendar(change=None):\n",
    "        \"\"\"Update calendar display\"\"\"\n",
    "        with calendar_output:\n",
    "            clear_output(wait=True)\n",
    "            html = create_clickable_calendar()\n",
    "            # Add details container\n",
    "            html += f'<div id=\"date-details-{symbol_dropdown.value}\" style=\"margin-top: 20px;\"></div>'\n",
    "            display(HTML(html))\n",
    "    \n",
    "    \n",
    "    # Set up event handlers\n",
    "    symbol_dropdown.observe(on_symbol_change, names='value')\n",
    "    year_dropdown.observe(update_calendar, names='value')\n",
    "    month_dropdown.observe(update_calendar, names='value')\n",
    "    prev_button.on_click(lambda b: navigate_month('prev'))\n",
    "    next_button.on_click(lambda b: navigate_month('next'))\n",
    "    \n",
    "    # Initial render\n",
    "    update_calendar()\n",
    "    \n",
    "    # Create layout\n",
    "    controls = widgets.HBox([\n",
    "        symbol_dropdown,\n",
    "        widgets.HBox([prev_button, next_button]),\n",
    "        year_dropdown,\n",
    "        month_dropdown\n",
    "    ], layout=widgets.Layout(justify_content='space-between', margin='10px 0'))\n",
    "    \n",
    "    # Legend\n",
    "    legend = widgets.HTML(\"\"\"\n",
    "    <div style=\"text-align: center; margin: 10px 0;\">\n",
    "        <span style=\"display: inline-block; margin: 0 15px;\">\n",
    "            <span style=\"display: inline-block; width: 20px; height: 20px; background: #4caf50; border-radius: 4px; vertical-align: middle; margin-right: 5px;\"></span>\n",
    "            Bullish\n",
    "        </span>\n",
    "        <span style=\"display: inline-block; margin: 0 15px;\">\n",
    "            <span style=\"display: inline-block; width: 20px; height: 20px; background: #f44336; border-radius: 4px; vertical-align: middle; margin-right: 5px;\"></span>\n",
    "            Bearish\n",
    "        </span>\n",
    "        <span style=\"display: inline-block; margin: 0 15px;\">\n",
    "            <span style=\"display: inline-block; width: 20px; height: 20px; background: #e0e0e0; border-radius: 4px; vertical-align: middle; margin-right: 5px;\"></span>\n",
    "            Neutral\n",
    "        </span>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create a simpler click handler using JavaScript that updates an HTML element\n",
    "    # We'll use a callback approach with ipywidgets\n",
    "    \n",
    "    \n",
    "    return widgets.VBox([\n",
    "        controls,\n",
    "        legend,\n",
    "        calendar_output\n",
    "    ])\n",
    "\n",
    "# Create and display the calendar widget\n",
    "if IPYWIDGETS_AVAILABLE:\n",
    "    print(\"Creating interactive calendar widget...\")\n",
    "    calendar_widget = create_calendar_widget(bias_results)\n",
    "    display(calendar_widget)\n",
    "else:\n",
    "    print(\"Cannot create calendar widget - ipywidgets not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44c8fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old calendar code removed - using React calendar app in calendar-app/ directory instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5672c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old calendar code removed - using React calendar app in calendar-app/ directory instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e126d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old calendar display code removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32ce61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old calendar display code removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd2ae988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old calendar display code removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb4cd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old calendar display code removed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}